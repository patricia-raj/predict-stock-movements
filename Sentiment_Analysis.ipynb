{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis Working Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624a41fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9895aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_news(ticker):\n",
    "    data_csv_path = Path(\"Resources/news/\" + ticker + \".csv\")\n",
    "    data_df = pd.read_csv(data_csv_path)\n",
    "    data_df['Date'] = pd.to_datetime(data_df['Date']).dt.date\n",
    "    data_df = data_df.groupby('Date')['Title', 'Description'].agg(lambda column: \". \".join(column))\n",
    "    return data_df\n",
    "    \n",
    "\n",
    "def get_ticker_price():\n",
    "    print('in progress...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47aad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment calculation based on compound score\n",
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(ticker):\n",
    "    get_ticker_news('NVDA')\n",
    "    data_df = data_df.reset_index()\n",
    "    title_sent = {\n",
    "    \"title_compound\": [],\n",
    "    \"title_pos\": [],\n",
    "    \"title_neu\": [],\n",
    "    \"title_neg\": [],\n",
    "    \"title_sent\": [],\n",
    "    }\n",
    "    text_sent = {\n",
    "    \"text_compound\": [],\n",
    "    \"text_pos\": [],\n",
    "    \"text_neu\": [],\n",
    "    \"text_neg\": [],\n",
    "    \"text_sent\": [],\n",
    "    }\n",
    "\n",
    "    # Get sentiment for the text and the title\n",
    "    for index, row in data_df.iterrows():\n",
    "        try:\n",
    "            # Sentiment scoring with VADER\n",
    "            title_sentiment = analyzer.polarity_scores(row[\"Title\"])\n",
    "            title_sent[\"title_compound\"].append(title_sentiment[\"compound\"])\n",
    "            title_sent[\"title_pos\"].append(title_sentiment[\"pos\"])\n",
    "            title_sent[\"title_neu\"].append(title_sentiment[\"neu\"])\n",
    "            title_sent[\"title_neg\"].append(title_sentiment[\"neg\"])\n",
    "            title_sent[\"title_sent\"].append(get_sentiment(title_sentiment[\"compound\"]))\n",
    "\n",
    "            text_sentiment = analyzer.polarity_scores(row[\"Description\"])\n",
    "            text_sent[\"text_compound\"].append(text_sentiment[\"compound\"])\n",
    "            text_sent[\"text_pos\"].append(text_sentiment[\"pos\"])\n",
    "            text_sent[\"text_neu\"].append(text_sentiment[\"neu\"])\n",
    "            text_sent[\"text_neg\"].append(text_sentiment[\"neg\"])\n",
    "            text_sent[\"text_sent\"].append(get_sentiment(text_sentiment[\"compound\"]))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    # Attaching sentiment columns to the News DataFrame\n",
    "    title_sentiment_df = pd.DataFrame(title_sent)\n",
    "    text_sentiment_df = pd.DataFrame(text_sent)\n",
    "    data_df = data_df.join(title_sentiment_df).join(text_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29aa933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\anaconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NVDA_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24204/13347565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mget_ticker_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NVDA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mNVDA_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#data_df.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NVDA_df' is not defined"
     ]
    }
   ],
   "source": [
    "ticker_list = ['AMZN','ARKK','JNJ','NVDA','TSLA','XOM']\n",
    "\n",
    "for ticker in ticker list:\n",
    "    get_sentiment_score(ticker)\n",
    "    \n",
    "\n",
    "#get_ticker_news('NVDA')\n",
    "#data_df = data_df.reset_index()\n",
    "\n",
    "\n",
    "#data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b36fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment scores dictionaries\n",
    "title_sent = {\n",
    "    \"title_compound\": [],\n",
    "    \"title_pos\": [],\n",
    "    \"title_neu\": [],\n",
    "    \"title_neg\": [],\n",
    "    \"title_sent\": [],\n",
    "}\n",
    "text_sent = {\n",
    "    \"text_compound\": [],\n",
    "    \"text_pos\": [],\n",
    "    \"text_neu\": [],\n",
    "    \"text_neg\": [],\n",
    "    \"text_sent\": [],\n",
    "}\n",
    "\n",
    "# Get sentiment for the text and the title\n",
    "for index, row in ticker_df.iterrows():\n",
    "    try:\n",
    "        # Sentiment scoring with VADER\n",
    "        title_sentiment = analyzer.polarity_scores(row[\"Title\"])\n",
    "        title_sent[\"title_compound\"].append(title_sentiment[\"compound\"])\n",
    "        title_sent[\"title_pos\"].append(title_sentiment[\"pos\"])\n",
    "        title_sent[\"title_neu\"].append(title_sentiment[\"neu\"])\n",
    "        title_sent[\"title_neg\"].append(title_sentiment[\"neg\"])\n",
    "        title_sent[\"title_sent\"].append(get_sentiment(title_sentiment[\"compound\"]))\n",
    "\n",
    "        text_sentiment = analyzer.polarity_scores(row[\"Description\"])\n",
    "        text_sent[\"text_compound\"].append(text_sentiment[\"compound\"])\n",
    "        text_sent[\"text_pos\"].append(text_sentiment[\"pos\"])\n",
    "        text_sent[\"text_neu\"].append(text_sentiment[\"neu\"])\n",
    "        text_sent[\"text_neg\"].append(text_sentiment[\"neg\"])\n",
    "        text_sent[\"text_sent\"].append(get_sentiment(text_sentiment[\"compound\"]))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Attaching sentiment columns to the News DataFrame\n",
    "title_sentiment_df = pd.DataFrame(title_sent)\n",
    "text_sentiment_df = pd.DataFrame(text_sent)\n",
    "ticker_df = ticker_df.join(title_sentiment_df).join(text_sentiment_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a648d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb07886",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['text_sent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e524787",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['title_sent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbe94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e50a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
